{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook enables you to train a chess embedding from scratch on GPU in Google Colab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!git clone https://github.com/patrickfrank1/chess-embedding-learning\n",
    "!cd chess-embedding-learning && git checkout colab-training\n",
    "!mv chess-embedding-learning/* /content/\n",
    "!rm chess-embedding-learning -rf\n",
    "%pip install -r requirements.txt\n",
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data\n",
    "!gdown --id 1_WnBplURUmIZDf3VAZmRGmI-QFJkjs2A\n",
    "!tar -xvf tensor_format.tar.bz2 -C /content/data\n",
    "!rm tensor_format.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero code training\n",
    "\n",
    "Train an embedding without writing any custom code. You can configure model hyperparameters in the code cell below.\n",
    "A few different model architectures are available out of the box, including dense neural networks and convolutional neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "preprocess:\n",
    "  pgn_path: ./data/pgn/lichess_db_standard_rated_2013-01.pgn\n",
    "  save_path: ./data/tensors/lichess_db_standard_rated_2013-01_v2.h5\n",
    "  game_filter: filter_out_bullet_games\n",
    "  game_processor: positions_to_tensor\n",
    "  chunk_size: 100000\n",
    "  number_games: 100\n",
    "train:\n",
    "  data:\n",
    "    train_dir: ./data/tensors/train\n",
    "    test_dir: ./data/tensors/test\n",
    "    train_batch_size: 256\n",
    "    test_batch_size: 256\n",
    "  model:\n",
    "    save_dir: ./models\n",
    "    train_steps_per_epoch: 20\n",
    "    test_steps_per_epoch: 5\n",
    "    loss: binary_crossentropy\n",
    "    tf_callbacks: [checkpoints]\n",
    "evaluate:\n",
    "  data:\n",
    "    model_dir: ./models\n",
    "    test_dir: ./data/tensors/test\n",
    "    test_batch_size: 64\n",
    "  eval:\n",
    "    number_examples: 10\n",
    "    result_dir: ./results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate model\n",
    "!python train_model.py --config config.yaml | tee train.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom training\n",
    "\n",
    "The cells below are a copy of the train_model.py script, but spread out and easily editable for convenience. You can use default function provided by the chesspos library or write your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "Provide an implementation for the `_define_encoder`, `_define_decoder`, and `_define_model` functions if you want to train an autoencoder. At least implement the `_define_model` function to train any neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "from chesspos.models.autoencoder import AutoencoderModel\n",
    "\n",
    "class CustomAutoencoder(AutoencoderModel):\n",
    "\tdef __init__(self, **kwargs):\n",
    "\t\tself.embedding_size = 256\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\n",
    "\tdef _model_helper(self) -> dict:\n",
    "\t\tencoder_input = layers.Input(shape=(8,8,15), dtype=tf.float16)\n",
    "\t\tencoder = layers.Reshape((8*8*15,))(encoder_input)\n",
    "\t\tencoder = layers.Dense(2*self.embedding_size, activation='relu')(encoder)\n",
    "\t\tencoder = layers.Dense(self.embedding_size, activation='relu')(encoder)\n",
    "\n",
    "\t\tdecoder_input = layers.Input(shape=(self.embedding_size,))\n",
    "\t\tdecoder = layers.Dense(2*self.embedding_size, activation='relu')(decoder_input)\n",
    "\t\tdecoder = layers.Dense(8*8*15, activation='relu')(decoder_input)\n",
    "\t\tdecoder = layers.Reshape((8,8,15))(decoder)\n",
    "\n",
    "\t\tencoder = keras.Model(inputs=encoder_input, outputs=encoder, name='encoder')\n",
    "\t\tdecoder = keras.Model(inputs=decoder_input, outputs=decoder, name='decoder')\n",
    "\t\tautoencoder = keras.Model(inputs=encoder_input, outputs=decoder(encoder(encoder_input)), name='autoencoder')\n",
    "\n",
    "\t\treturn {'encoder': encoder, 'decoder': decoder, 'autoencoder': autoencoder}\n",
    "\n",
    "\tdef _define_encoder(self) -> Model:\n",
    "\t\treturn self._model_helper()['encoder']\n",
    "\n",
    "\tdef _define_decoder(self):\n",
    "\t\treturn self._model_helper()['decoder']\n",
    "\n",
    "\tdef _define_model(self) -> Model:\n",
    "\t\treturn self._model_helper()['autoencoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configuration\n",
    "\n",
    "Customize the training setup and run the training. First define how the training tensors should be preprocessed for the neural network. The provided samples encode a chess position as tensor of shape (8, 8, 15). Each plane represents a (piece, color) combination. The 13th plane encodes the castling rights. The 14th plane encodes the en passant square. The 15th plane encodes the side to move.\n",
    "\n",
    "Here we give a simple example on how to preprocess the training tensors for the network defines above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from chess import Board\n",
    "from chesspos.preprocessing import board_to_tensor, tensor_to_board\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network needs the same sample as input and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sample_preprocessor(samples: np.ndarray) -> Tuple[np.ndarray]:\n",
    "\treturn tuple([samples, samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to analyse the autoencoder encodings, we need to define how to convert chess boards into input tensors and vice versa. Here we basically need to wrap the sample in a batch with size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_board_to_input(board: Board) -> np.ndarray:\n",
    "\treturn np.expand_dims(board_to_tensor(board), axis=0)\n",
    "\n",
    "def custom_tensor_to_board(tensor: np.ndarray) -> Board:\n",
    "\treturn tensor_to_board(tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import chess\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from chesspos.preprocessing import SampleGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = yaml.safe_load(open('config.yaml'))['train']\n",
    "evaluate_params = yaml.safe_load(open('config.yaml'))['evaluate']\n",
    "\n",
    "data_params = train_params['data']\n",
    "model_params = train_params['model']\n",
    "evaluate_data_params = evaluate_params['data']\n",
    "evaluate_eval_params = evaluate_params['eval']\n",
    "\n",
    "train_generator = SampleGenerator(\n",
    "\tsample_dir = data_params['train_dir'],\n",
    "\tsample_preprocessor = custom_sample_preprocessor,\n",
    "\tbatch_size = data_params['train_batch_size'],\n",
    "\tsample_type = np.float32,\n",
    ")\n",
    "\n",
    "test_generator = SampleGenerator(\n",
    "\tsample_dir = data_params['test_dir'],\n",
    "\tsample_preprocessor = custom_sample_preprocessor,\n",
    "\tbatch_size = data_params['test_batch_size'],\n",
    "\tsample_type = np.float32,\n",
    ")\n",
    "\n",
    "autoencoder = CustomAutoencoder(\n",
    "\ttrain_generator=train_generator,\n",
    "\ttest_generator=test_generator,\n",
    "\ttrain_steps_per_epoch=model_params['train_steps_per_epoch'],\n",
    "\ttest_steps_per_epoch=model_params['test_steps_per_epoch'],\n",
    "\tsave_dir=model_params['save_dir'],\n",
    "\toutput_to_board = custom_tensor_to_board,\n",
    "\tboard_to_input = custom_board_to_input,\n",
    "\tloss = model_params['loss'],\n",
    "\ttf_callbacks = model_params['tf_callbacks'] + [\n",
    "\t\tkeras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.005, patience=10, verbose=1, mode='min', restore_best_weights=True),\n",
    "\t\tkeras.callbacks.TensorBoard(log_dir=model_params['save_dir'], histogram_freq=1, write_images=True, embeddings_freq=1)\n",
    "\t]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.train()\n",
    "autoencoder.save()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load()\n",
    "number_examples = evaluate_eval_params['number_examples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the samples with the lowest reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.plot_best_samples(number_samples=number_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the samples with the highest reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.plot_worst_samples(number_samples=number_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate between two sample positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board1 = chess.Board()\n",
    "board2 = chess.Board(\"rnbq1rk1/ppp1bppp/4pn2/3p4/2PP4/5NP1/PP2PPBP/RNBQ1RK1 b - - 0 6\")\n",
    "\n",
    "sample1 = custom_board_to_input(board1)\n",
    "sample2 = custom_board_to_input(board2)\n",
    "autoencoder.interpolate(sample1=sample1, sample2=sample2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
